#!/usr/bin/env python3
"""
The automatic database generation for TensorAlloy.
"""
import numpy as np
import toml
import os
import json
import tqdm
import matplotlib
from datetime import datetime
from pathlib import Path
from ase.io import read, write
from ase import Atoms
from ase.build import bulk
from ase.calculators.vasp import Vasp
from ase.units import GPa, kB
from ase.neighborlist import neighbor_list
from argparse import ArgumentParser
from tensoralloy.io.vasp import read_vasp_xml
from tensordb.vaspkit import ServiceUnit, VaspJob
from tensordb.sampler import VaspAimdSampler, VaspHighPrecDftCalculator
from tensordb.utils import getitem
from matplotlib import pyplot as plt


class TensorDB:
    """
    The database generation kit for TensorAlloy.
    """

    def __init__(self, input_file):
        """
        Initialization method.
        """
        self.input_file = input_file
        self.root = Path(input_file).parent
        self.config = dict(toml.load(input_file))
        if self.config.get("finite_temperature", False):
            self.is_finite_temperature = True
        else:
            self.is_finite_temperature = False
        self.species = self.config["species"]
        self.phases = self.config["phases"]
        self.base_phase_structures = self.init_phases()
        self.init_vasp()
        self.aimd_sampler = VaspAimdSampler(self.config)
        self.porous_sampler = None
        self.dft_calculator = VaspHighPrecDftCalculator(self.config)

    def init_phases(self):
        """
        Initialize the base phase structures.
        """
        workdir = self.root / "structures"
        if not workdir.exists():
            raise IOError(f"Cannot find the directory 'structures' in {str(self.root)}")
        structures = {}
        for phase in self.config["phases"]:
            if phase == "liquid":
                structures[phase] = self.init_liquid_structure()
            else:
                candidates = [x for x in workdir.glob(f"{phase}.*")]
                if len(candidates) == 0:
                    raise ValueError(f"Cannot find the poscar for {phase}")
                if len(candidates) > 1:
                    raise ValueError(f"Multiple poscars for {phase}")
                poscar = candidates[0]
                structures[phase] = read(str(poscar))
        return structures

    def init_liquid_structure(self):
        """
        Initialize the liquid phase structure.

        Num species = 1: use the fcc phase.
        Num species > 1: use SAE (todo)

        """
        if len(self.species) == 1:
            veq = self.config["liquid"]["veq"]
            a = (4 * veq) ** (1 / 3)
            return bulk(self.species[0], crystalstructure="fcc", a=a, cubic=True)
        else:
            raise NotImplementedError(
                "Liquid phase for multi-species is not implemented yet."
            )

    def get_base_structure(self, phase: str) -> Atoms:
        """
        Get the base phase structure.
        """
        return self.base_phase_structures[phase].copy()

    def get_supercells_at_volume(self, phase: str, volume: float) -> Atoms:
        """
        Get the supercell structure at the given atomic volume.
        """
        base = self.get_base_structure(phase)
        scale = (volume / base.get_volume() * len(base)) ** (1 / 3)
        base.set_cell(base.get_cell() * scale, scale_atoms=True)
        supercells = []
        for replicate in self.config[phase]["supercell"]:
            supercells.append(base * replicate)
        return supercells

    def init_vasp(self):
        """
        Initialize the base VASP calculator.
        """
        params = getitem(self.config, ["vasp", "pot"])

        # Setup the POTCARs path
        os.environ["VASP_PP_PATH"] = params["pp_path"]

        # Setup PORCAR for each specie.
        # For ASE VASP calculator, only the suffix is used.
        setups = {}
        if "potcars" in params:
            for i, potcar in enumerate(params["potcars"]):
                if potcar != self.species[i]:
                    setups[self.species[i]] = potcar[len(self.species[i]):]
        else:
            setups["base"] = "recommended"
        xc = params.get("xc", "pbe")

        # The NBANDS for VASP calculations.
        self.vasp_nbands = {}

        # Initialize the VASP calculator for AIMD sampling jobs.
        params = getitem(self.config, ["vasp", "sampling"])
        self.vasp = Vasp(
            xc=xc,
            setups=setups,
            ediff=params.get("ediff", 1e-5),
            lreal=params.get("lreal", "Auto"),
            prec=params.get("prec", "Normal"),
            encut=params.get("encut", 400),
            ismear=params.get("ismear", 1),
            sigma=params.get("sigma", 0.1),
            algo=params.get("algo", "normal"),
            isym=params.get("isym", 0),
            nelmin=params.get("nelmin", 4),
            isif=params.get("isif", 2),
            ibrion=params.get("ibrion", 0),
            nsw=params.get("nsw", 5000),
            potim=params.get("potim", 1),
            nwrite=params.get("nwrite", 1),
            lcharg=params.get("lcharg", False),
            lwave=params.get("lwave", False),
            nblock=params.get("nblock", 1),
        )
        if "npar" in params:
            self.vasp.set(npar=params["npar"])
        if "kpar" in params:
            self.vasp.set(kpar=params["kpar"])
        if "ncore" in params:
            self.vasp.set(ncore=params["ncore"])
        self.vasp_nbands["sampling"] = params.get("nbands", None)

        # Initialize the VASP calculator for high-precision DFT calculations.
        params = getitem(self.config, ["vasp", "calc"])
        self.prec_vasp = Vasp(
            xc=params.get("xc", "pbe"),
            setups=setups,
            ediff=params.get("ediff", 1e-6),
            lreal=params.get("lreal", False),
            kspacing=params.get("kspacing", 0.2),
            prec=params.get("prec", "Accurate"),
            encut=params.get("encut", 500),
            ismear=params.get("ismear", 1),
            sigma=params.get("sigma", 0.05),
            algo=params.get("algo", "normal"),
            isym=params.get("isym", 0),
            nelmin=params.get("nelmin", 4),
            isif=params.get("isif", 2),
            ibrion=params.get("ibrion", -1),
            nsw=params.get("nsw", 1),
            nwrite=params.get("nwrite", 1),
            lcharg=params.get("lcharg", False),
            lwave=params.get("lwave", False),
            nblock=params.get("nblock", 1),
        )
        if "npar" in params:
            self.prec_vasp.set(npar=params["npar"])
        if "kpar" in params:
            self.prec_vasp.set(kpar=params["kpar"])
        if "ncore" in params:
            self.prec_vasp.set(ncore=params["ncore"])
        self.vasp_nbands["calc"] = params.get("nbands", None)

    # --------------------------------------------------------------------------
    # Iterators
    # --------------------------------------------------------------------------

    def sampling_task_iterator(self):
        """
        Iterate through all AIMD sampling job dirs.
        """
        workdir = self.root / "sampling"
        return workdir.glob("*/n[pv]t/*/*_*K_to_*K")

    def accurate_dft_calc_iterator(self):
        """
        Iterate through all high precision dft calculation job dirs.
        """
        workdir = self.root / "calc"
        return workdir.glob("*atoms/group*/task*")

    # --------------------------------------------------------------------------
    # Generate VASP AIMD sampling jobs
    # --------------------------------------------------------------------------

    def create_vasp_sampling_nvt_tasks(self, override=False):
        """
        Create VASP Langeven NVT sampling jobs: gamma-only.
        """
        self.aimd_sampler.create_vasp_sampling_nvt_tasks(override=override)

    def create_vasp_sampling_npt_tasks(self, override=False):
        """
        Create VASP Parrinello-Rahman NPT sampling jobs
        """
        self.aimd_sampler.create_vasp_sampling_npt_tasks(override=override)

    # --------------------------------------------------------------------------
    # Check the status of sampling jobs
    # --------------------------------------------------------------------------

    def update_status_of_sampling_job(self, jobdir: Path):
        """
        Update and return the status of a sampling job at given jobdir.
        """
        self.aimd_sampler.update_status_of_sampling_job(jobdir)

    def get_status_of_all_sampling_jobs(self):
        """
        Get the status of all sampling jobs.
        """
        self.aimd_sampler.get_status_of_all_sampling_jobs()

    def list_unsubmitted_sampling_jobs(self):
        """
        List unsubmitted AIMD sampling jobs.
        """
        self.aimd_sampler.list_unsubmitted_sampling_jobs()

    # --------------------------------------------------------------------------
    # Post-processing
    # --------------------------------------------------------------------------

    def post_process_sampling_job(self, jobdir: Path):
        """
        Post-processing a sampling job.
        """
        self.aimd_sampler.post_process_sampling_job(jobdir)

    def post_process_all_sampling_jobs(self):
        """
        Post-processing all sampling jobs.
        """
        self.aimd_sampler.post_process_all_sampling_jobs()

    # --------------------------------------------------------------------------
    # High-precision DFT calculations
    # --------------------------------------------------------------------------

    def create_vasp_accurate_dft_tasks(self, interval=50, shuffle=False):
        """
        Create VASP high precision DFT calculation tasks.
        """
        self.dft_calculator.create_vasp_accurate_dft_tasks(
            interval=interval, shuffle=shuffle)

    def get_accurate_dft_calculation_status(self):
        """
        Get the status of high precision dft calculations.
        """
        self.dft_calculator.get_accurate_dft_calculation_status()
        
    # --------------------------------------------------------------------------
    # Make the training dataset
    # --------------------------------------------------------------------------

    def _gather_one(self, taskdir: Path, check_job_status=False):
        """
        Gather one completed high precision DFT calculation.
        """
        if check_job_status:
            job = VaspJob(taskdir)
            su = job.get_vasp_job_service_unit()
            if su is None:
                return None
            converged = job.check_vasp_job_scf_convergence()
            if not converged:
                return None
        else:
            metadata = taskdir / "metadata.json"
            if not metadata.exists():
                return None
            with open(metadata, "r") as fp:
                metadata = json.load(fp)
            if not metadata.get("converged", False):
                return None
            if not metadata.get("SU", {}):
                return None
            su = ServiceUnit(**metadata["SU"])
            if su.hours <= 0:
                return None
        atoms = next(read_vasp_xml(taskdir / "vasprun.xml", 
                                   finite_temperature=self.is_finite_temperature, 
                                   index=0))
        atoms.info["hash"] = metadata["hash"]
        atoms.info["aid"] = metadata["aid"]
        atoms.info["group_id"] = metadata["group_id"]
        atoms.info["task_id"] = metadata["task_id"]
        return atoms

    def gather(self, output_file=None, nprocs=-2, check_job_status=False):
        """
        Gather all completed high precision DFT calculations into a single file.

        Parameters
        ----------
        output_file : str
            The output file name.
        nprocs : int
            The number of processes to use. Default is -2, which means using all
            available CPUs but one.
        check_job_status : bool
            Check the job status before gathering. Default is False.

        """
        from joblib import Parallel, delayed

        all_tasks = [x for x in self.accurate_dft_calc_iterator()]
        objects = Parallel(n_jobs=nprocs, verbose=1)(
            delayed(self._gather_one)(taskdir, check_job_status)
            for taskdir in all_tasks
        )
        objects = [x for x in objects if x is not None]
        print(f"[VASP/gather]: total {len(objects)} structures gathered")

        if output_file is None:
            date = datetime.now().strftime("%Y%m%d")
            output_dir = self.root / "database"
            output_dir.mkdir(exist_ok=True)
            output_file = output_dir / f"database_N{len(objects)}_{date}.extxyz"
        write(output_file, objects, format="extxyz")

    # --------------------------------------------------------------------------
    # Plot
    # --------------------------------------------------------------------------

    def plot(self, filename: Path, figname=None, rcut=6.0):
        """
        Plot the database file. Currently, four plots are generated:

        1. Energy vs. Volume
        2. Force Norm vs. Volume
        3. Energy vs. Pressure
        4. Force Norm vs. Pressure

        """
        from scipy.stats import gaussian_kde
        from ase.db import connect

        if filename.suffix == ".db":
            db = connect(filename)
            trajectory = []
            for i in range(len(db)):
                atoms = db.get_atoms(id=i + 1, add_additional_information=True)
                trajectory.append(atoms)
        else:
            trajectory = read(filename, index=":")
        energies = []
        forces = []
        fnorms = []
        volumes = []
        stresses = []
        pressures = []
        rdf = {}
        temperatures = []
        for atoms in tqdm.tqdm(trajectory):
            natoms = len(atoms)
            volumes.append(atoms.get_volume() / natoms)
            energies.append(atoms.get_potential_energy() / natoms)
            forces.extend(atoms.get_forces().flatten().tolist())
            fnorms.append(np.sqrt(np.sum(atoms.get_forces() ** 2) / natoms))
            stresses.extend(atoms.get_stress(voigt=True).flatten().tolist())
            pressures.append(atoms.get_stress(voigt=True)[:3].mean() / -GPa)
            if self.is_finite_temperature:
                temperatures.append(atoms.info["etemperature"] / kB)
            species = atoms.get_chemical_symbols()
            ilist, jlist, dlist = neighbor_list("ijd", atoms, cutoff=rcut)
            for i, j, d in zip(ilist, jlist, dlist):
                key = tuple(sorted((species[i], species[j])))
                if key not in rdf:
                    rdf[key] = []
                rdf[key].append(d)

        volumes = np.asarray(volumes)
        pressures = np.asarray(pressures)
        energies = np.asarray(energies)
        forces = np.asarray(forces)
        fnorms = np.asarray(fnorms)
        stresses = np.asarray(stresses)

        for key in rdf:
            rdf[key] = np.asarray(rdf[key])

        _, axes = plt.subplots(2, 3, figsize=(12, 7))
        cmap = matplotlib.colormaps["viridis"]

        ax = axes[0, 0]
        ax.plot(volumes, energies, "o", markersize=2, color=cmap(0.0))
        ax.set_xlabel("Volume ($\AA^3$)")
        ax.set_ylabel("Energy (eV/atom)")

        ax = axes[0, 1]
        ax.plot(volumes, fnorms, "o", markersize=2, color=cmap(0.2))
        ax.set_xlabel("Volume ($\AA^3$)")
        ax.set_ylabel("Force norm (eV/$\AA$)")

        ax = axes[0, 2]
        density = gaussian_kde(volumes)
        x = np.linspace(volumes.min(), volumes.max(), 100)
        fx = density(x)
        ax.plot(x, fx, label="Volume")
        ax.set_xlabel("Volume ($\AA^3$)")
        ax.set_ylabel("Scaled Density")
    
        if self.is_finite_temperature:
            ax = axes[1, 0]
            ax.plot(volumes, temperatures, "o", markersize=2)
            ax.set_xlabel("Volume ($\AA^3$)")
            ax.set_ylabel("Temperature (K)")

            ax = axes[1, 1]
            ax.plot(pressures, temperatures, "o", markersize=2)
            ax.set_xlabel("Pressure (GPa)")
            ax.set_ylabel("Temperature (K)")
        else:
            ax = axes[1, 0]
            ax.plot(pressures, energies, "o", markersize=2, color=cmap(0.6))
            ax.set_xlabel("Pressure (GPa)")
            ax.set_ylabel("Energy (eV/atom)")

            ax = axes[1, 1]
            ax.plot(pressures, fnorms, "o", markersize=2, color=cmap(0.8))
            ax.set_xlabel("Pressure (GPa)")
            ax.set_ylabel("Force norm (eV/$\AA$)")

        ax = axes[1, 2]
        for key in rdf:
            density = gaussian_kde(rdf[key], weights=1.0 / rdf[key])
            x = np.linspace(0, 6, 100)
            fx = density(np.linspace(0, 6, 100))
            ax.plot(x, fx, label=f"{key[0]}-{key[1]}")
        ax.legend()
        ax.set_xlabel("Distance ($\AA$)")
        ax.set_ylabel("Scaled Density")

        plt.tight_layout()

        if figname is None:
            figname = filename.parent / filename.name.replace(filename.suffix, ".png")
        plt.savefig(figname, dpi=150)
        plt.close()


def main():
    root_parser = ArgumentParser()

    # Common arguments
    root_parser.add_argument(
        "-i", "--input", default="config.toml", help="The input file"
    )

    # Subparsers
    sub_parsers = root_parser.add_subparsers(dest="command", help="Sub-commands")

    # The subparser for creating DFT jobs
    parser = sub_parsers.add_parser("create")
    parser.add_argument("task", choices=["sampling", "calc"], 
                        help="The type of the DFT jobs to create.")
    parser.add_argument(
        "--interval", 
        type=int, 
        default=50, 
        help="The interval (in timesteps) for fetching snapshots from AIMD "
             "trajectories. Only valid for 'calc' tasks.")
    parser.add_argument(
        "--nvt", 
        default=False,
        action="store_true", 
        help="Create NVT sampling jobs. Only valid for 'sampling' tasks.")
    parser.add_argument(
        "--npt", 
        default=False,
        action="store_true", 
        help="Create NPT sampling jobs. Only valid for 'sampling' tasks.")

    # The subparser for AIMD sampling
    parser = sub_parsers.add_parser(
        "sampling", help="Commands for creating sampling tasks."
    )
    parser.add_argument(
        "--ensemble",
        choices=["nvt", "npt"],
        nargs="+",
        default=["nvt", "npt"],
        help="The MD ensemble to use, nvt or npt.",
    )

    # The subparser for getting task status
    parser = sub_parsers.add_parser("status", help="Comannds for getting task status.")
    parser.add_argument(
        "type",
        choices=["sampling", "calc", "unsubmitted"],
        help="Choose the type of status: sampling for AIMD sampling jobs, calc for "
             "high precision DFT calculations, unsubmitted for unsubmitted jobs.",
    )

    # The subparser for plotting
    parser = sub_parsers.add_parser("plot", help="")
    parser.add_argument("filename", type=Path, help="The database file to plot.")
    parser.add_argument("--rcut", type=float, default=6.0, help="The cutoff radius.")

    # The subparser for the post-processing
    parser = sub_parsers.add_parser("postprocess")
    
    # The subparser for gathering calculated results
    parser = sub_parsers.add_parser("gather")

    # Parse the arguments
    args = root_parser.parse_args()
    db = TensorDB(args.input)
    
    if args.command == "create":
        if args.task == "sampling":
            if not (args.nvt or args.npt):
                print("Please specify at least one ensemble, e.g., appending "
                      "--nvt or --npt to the command.")
            if args.nvt:
                db.create_vasp_sampling_nvt_tasks()
            if args.npt:
                db.create_vasp_sampling_npt_tasks()
        elif args.task == "calc":
            db.create_vasp_accurate_dft_tasks(interval=args.interval)
    elif args.command == "status":
        if args.type == "sampling":
            db.get_status_of_all_sampling_jobs()
        elif args.type == "calc":
            db.get_accurate_dft_calculation_status()
        elif args.type == "unsubmitted":
            db.list_unsubmitted_sampling_jobs()
    elif args.command == "postprocess":
        db.post_process_all_sampling_jobs()
    elif args.command == "gather":
        db.gather()
    elif args.command == "plot":
        db.plot(filename=args.filename, rcut=args.rcut)


if __name__ == "__main__":
    main()
